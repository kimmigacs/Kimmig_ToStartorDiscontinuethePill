{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314276ae",
   "metadata": {},
   "source": [
    "# Shen-Atlas regionswise RSA within groups - anonymized version\n",
    "### model: behavior_delta - positive and negative mood, depressive symptoms and emotion recognition performance\n",
    "### Note: code cannot be run as a whole - the desired variables to be compared have to be selected manually by running the respective cells\n",
    "#### import modules & correct read-in (+split groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import system as oss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "#from sklearn import metrics\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import permutation_test\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003bfb3",
   "metadata": {},
   "source": [
    "## Modelling - creating dataframes\n",
    "### Parcel-wise Resting State Connectivity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9953525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read in Change in Resting State Connectivity Dataframe \n",
    "### HDFstore\n",
    "DF = pd.read_hdf('ParcelwiseConnectivityDelta_Shen268_anonymized.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92d07",
   "metadata": {},
   "source": [
    "### Run one dataframe to be compared (e.g. positive mood or negative mood or depression or emotion recognition) with resting state connectivity\n",
    "#### Load Itemwise positive mood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51dd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in behav data - Positive Mood\n",
    "df_behav_neworder = pd.read_excel('HormonesBehaviorDelta_anonymized.xlsx', sheet_name = 'PANASpos_DeltaperItem', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d769f2e",
   "metadata": {},
   "source": [
    "#### Load Itemwise negative mood data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in behav data - Negative Mood\n",
    "df_behav_neworder = pd.read_excel('HormonesBehaviorDelta_anonymized.xlsx', sheet_name = 'PANASneg_DeltaperItem', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a001b",
   "metadata": {},
   "source": [
    "#### Load Itemwise depression score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in behav data - Depressive Symptoms\n",
    "df_behav_neworder = pd.read_excel('HormonesBehaviorDelta_anonymized.xlsx', sheet_name = 'BDI_DeltaperItem', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1fcd70",
   "metadata": {},
   "source": [
    "#### Load Itemwise emotion recognition accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in behav data - Emotion Recognition Accuracy\n",
    "df_behav_neworder = pd.read_excel('HormonesBehaviorDelta_anonymized.xlsx', sheet_name = 'EmoRecogAcc_DeltaperItem', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ac2f2",
   "metadata": {},
   "source": [
    "#### Load Itemwise emotion recognition response times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in behav data - Emotion Recognition Response Times\n",
    "df_behav_neworder = pd.read_excel('HormonesBehaviorDelta_anonymized.xlsx', sheet_name = 'EmoRecogRT_DeltaperEmotion', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behav_neworder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a567b95",
   "metadata": {},
   "source": [
    "### Drop participants with missing behavioral data from both dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40b46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce data_behav to have the same participants as in RSA by excluding missing data\n",
    "SubjectswithNAN_behav = df_behav_neworder.loc[pd.isna(df_behav_neworder).any(1), :].index\n",
    "df_behavFIN = df_behav_neworder.drop(index=SubjectswithNAN_behav)\n",
    "#make sure that participants without behavioral data are also dropped from RS dataframe\n",
    "DF_fin = DF.drop(index=SubjectswithNAN_behav)        \n",
    "# compare whether both dataframes include the same participants \n",
    "if DF_fin.index.equals(df_behavFIN.index):\n",
    "    print(\"dataframes have the same order and number of participants\")\n",
    "else:\n",
    "    print(\"needs checking\") \n",
    "#len(df_hormonesdeltaFIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behavFIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_fin\n",
    "#len(DF_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497448e",
   "metadata": {},
   "source": [
    "## Regionwise RSA approach - creating and comparing RDMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52312f29",
   "metadata": {},
   "source": [
    "### Create RDM for behavioral change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41cd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute RDM for behavioral changes using standardized Euclidean distance\n",
    "rdm_modelFull = pairwise_distances(df_behavFIN.to_numpy(), metric='seuclidean')\n",
    "DF_rdm_modelFull = pd.DataFrame(rdm_modelFull)\n",
    "# vectorize\n",
    "rdm_modelFull_vec = DF_rdm_modelFull.to_numpy()[np.triu_indices(len(DF_rdm_modelFull.to_numpy()[0]), 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de637b9c",
   "metadata": {},
   "source": [
    "###  Visualize behavioral RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f527004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask dataframe\n",
    "mask = np.zeros_like(DF_rdm_modelFull, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "#ax = sns.heatmap(DF_rdm_hormone_visualize, mask=mask, yticklabels=False, xticklabels=False, cbar=False, vmin = 0, vmax = 10)\n",
    "ax = sns.heatmap(DF_rdm_modelFull, mask=mask, yticklabels=False, xticklabels=False, cbar=False, square=True)\n",
    "# use matplotlib.colorbar.Colorbar object\n",
    "#cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "#cbar.ax.tick_params(labelsize=20)\n",
    "#plt.show()\n",
    "#make background transparent\n",
    "#cbar.patch.set_alpha(0)\n",
    "ax.patch.set_alpha(0)\n",
    "\n",
    "print(DF_rdm_modelFull.shape)\n",
    "\n",
    "# save RDM figure, if needed\n",
    "#plt.savefig('C:/Users/UKPP/Documents/HormonesRestingStateRSA/ManuscriptRSA_posmoodRDM_standEuclidean.jpg', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#get info of min and max values as well as matrix size\n",
    "x = DF_rdm_modelFull.to_numpy()\n",
    "print(np.max(x[np.nonzero(x)]))\n",
    "print(np.min(x[np.nonzero(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4c1b8",
   "metadata": {},
   "source": [
    "### Create RDMs per parcel - functions and loop over all parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define function to get features of one parcel for one participant\n",
    "def comp_parcel_feat(all_feat,parcel):\n",
    "    '''\n",
    "    get vector (represents connectivity of chosen parcel to every other parcel) for one participant\n",
    "    '''\n",
    "    n = len(all_feat)\n",
    "    N = (math.sqrt(8*n+1)+1)/2\n",
    "    sq = np.zeros((int(N),int(N)))\n",
    "    zw = np.ones((int(N),int(N)))\n",
    "    zw2 = np.tril(zw, k=-1)\n",
    "    i = np.where(zw2 == 1)\n",
    "    i_arr = np.asarray(i)\n",
    "    for nb in range(n):\n",
    "        sq[i_arr[0,nb],i_arr[1,nb]] = all_feat[nb]       \n",
    "    sq = sq + sq.T\n",
    "    parcel_feat = sq[parcel,:]\n",
    "    features = np.delete(parcel_feat, parcel)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd1aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Regionswise approach\n",
    "'''\n",
    "the code below gets the connectivity per region and calculates the RSA between the model \n",
    "and the regionwise connectivity. \n",
    "'''\n",
    "##############################\n",
    "\n",
    "####### prepare looop\n",
    "# vessel\n",
    "all_parcs = {}\n",
    "all_parcsDF = {}\n",
    "all_parcsDF_resUncor = {}\n",
    "all_parcsDF_resPerm = {} \n",
    "all_parcsDF_RDM = {}\n",
    "temp_rdm_df_vec = {}\n",
    "\n",
    "### loop over parcel\n",
    "'''\n",
    "the following double-loop loops over parcels and participants to create\n",
    "a) parselwise RDM \n",
    "b) parcelwise result (RSA distance to model, defined above)\n",
    "'''\n",
    "# definitions\n",
    "parc = []\n",
    "parcel_ID = range(0, 268) # vector with parcel numbers 268\n",
    "# loop over parcelID\n",
    "for parc in parcel_ID:\n",
    "    print('- parcel: {ID}, loop over parcels (step 1/4) -'.format(ID=parc))\n",
    "    all_parcs[str(parc)] = {}\n",
    "# loop over subjects in DF_fin\n",
    "    for subj in DF_fin.index.to_list():\n",
    "        all_parcs[str(parc)][subj] = comp_parcel_feat(DF_fin.loc[subj].to_numpy(), parc)\n",
    "# when done looping over subjects, make DFs out of the sub-dictionary\n",
    "    print('-- parcel: {ID}, save parcel connectivity as DF in vessel (step 2/4)'.format(ID=parc))\n",
    "    all_parcsDF[str(parc)] = pd.DataFrame.from_dict(all_parcs[str(parc)]).T\n",
    "# compute and save RDM for distinct parcels\n",
    "    print('-- parcel: {ID}, compute and save RDM (step 3/4)'.format(ID=parc))\n",
    "    temp_rdm = pairwise_distances(all_parcsDF[str(parc)].to_numpy(), metric='euclidean'); \n",
    "    all_parcsDF_RDM[str(parc)] = pd.DataFrame(temp_rdm)\n",
    "# vectorize parcelRDM\n",
    "    temp_rdm_df_vec[str(parc)] = all_parcsDF_RDM[str(parc)].to_numpy()[np.triu_indices(len(all_parcsDF_RDM[str(parc)].to_numpy()[0]), 1)]\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parcsDF[str(24)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ddc811",
   "metadata": {},
   "source": [
    "### Visualize parcelwise RSFC RDMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca59b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "parc = []\n",
    "parcel_ID = [24]  # Vector with example parcel numbers\n",
    "\n",
    "# Loop over parcel_ID\n",
    "for parc in parcel_ID:\n",
    "    # Mask dataframe\n",
    "    mask = np.zeros_like(all_parcsDF_RDM[str(parc)], dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Plot heatmap with masked upper triangle and diagonal\n",
    "    ax = sns.heatmap(all_parcsDF_RDM[str(parc)], mask=mask, yticklabels=False, xticklabels=False, cbar=False, square=True)\n",
    "\n",
    "    # Make background transparent\n",
    "    ax.patch.set_alpha(0)\n",
    "\n",
    "    print(all_parcsDF_RDM[str(parc)].shape)\n",
    "\n",
    "    # Save figure if needed\n",
    "    # plt.savefig('ManuscriptRSA_BrainRDM_Euclidean_parcel{value}_nolabels.jpg'.format(value=parc+1), bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e81457",
   "metadata": {},
   "source": [
    "## RSA - with permutation testing (10'000 permutations)\n",
    "\n",
    "**Permutation Testing**\n",
    "\n",
    "Using permutation testing to evaluate the significance of RSA analyses (Spearman correlations) via Family-Wise Error (FWE) correction\n",
    "\n",
    "For each of the 268 parcels: \n",
    "\n",
    "(1) subject labels (i.e., rows and columns) are randomly reordered/permuted for one of the two similarity matrices (behavioral RDM) a large number of times (in this case, 10'000)\n",
    "\n",
    "(2) the correlation between the two matrices (permuted behavioral RDM and original brain RDM) is calculated - this is done 10'000 times - and this forms a null distribution of 10'000 surrogate correlation values\n",
    "\n",
    "(3) Create a family-wise null distribution of 10'000 values by pooling the 268 null distributions and taking the maximum value for each of the 10'000 positions of the 268 null distributions \n",
    "\n",
    "(4) the true correlation values (between the original behavioral RDM and the original brain RDM) is calculated and the observed correlation coefficient is then compared to this family-wise null distribution to obtain a new p-value (assessed at a 0.05 significance threshold, as the FWE correction is done by assessing the ture correlation against a family-wise null distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aff9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ### define function to calculate location of true correlation coefficient in the winner null distribution\n",
    "def calc_pvalue(null_distr, value):\n",
    "    \n",
    "    ''' \n",
    "    Function that calculates the p value of a given value on a self made null distribution, i.e. the probability that \n",
    "    that value is observed if the null hypothesis is true\n",
    "    \n",
    "    null_distr is a list\n",
    "    value needs to be a single value (so careful when computing correlation, need to feed in only the correlation coefficent and exclude p-value)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Compute the percentile rank of a score relative to a array of scores (here it's the scores making up the null distribution)\n",
    "    percentile = scipy.stats.percentileofscore(np.asarray(null_distr), value, kind = 'rank')\n",
    "    #print(percentile)\n",
    "    formatted_percentile = \"{:.16f}\".format(percentile)\n",
    "    #print(formatted_percentile)\n",
    "    \n",
    "    # The corresponding p-value\n",
    "    p_value = (100 - percentile)/100\n",
    "    #print(p_value)\n",
    "    formatted_p_value = \"{:.16f}\".format(p_value)\n",
    "    #print(formatted_p_value)\n",
    "    \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337541b",
   "metadata": {},
   "source": [
    "### Create null distributions and test true statistic against null distribution of 'winners' across the parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba984a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Permutation testing - same permutation for all parcels 10000 times and then take for each the 'winner'\n",
    "perm_num = 10000\n",
    "parcel_ID = range(0, 268)\n",
    "parc = [] # empty from previous cells\n",
    "\n",
    "# vessel for the family-wise null distribution of correlation coefficients \n",
    "family_wise_null_distr_behav = []\n",
    "\n",
    "## this is not necessary as the family-wise null distribution will be created in the loop already, but this will be used to later re-build the 268 null distributions by parcel (to check that code worked according to plan)\n",
    "# creating vessel that will each contain a list of lists representing r values for a given permutation\n",
    "# called \"to transpose\" because we will want to make it an array and then .T the array so that it represents a list of lists representing the null distributions made across 268 conditions \n",
    "list_null_distr_to_transpose = []\n",
    "\n",
    "\n",
    "for i in range(perm_num):\n",
    "        \n",
    "    ## Creating the permuted behavioral RDM\n",
    "    # creating an array of weights ('factors') to reorder the rows and columns of the behavioral/hormonal RDM\n",
    "    perm_fact_behav = np.random.permutation(np.eye(len(DF_rdm_modelFull),dtype=int))\n",
    "    # creating the reordered (permutated) behavioral matrix based on the original RDM and the above created factors\n",
    "    df_behav_corrected_perm = (perm_fact_behav @ DF_rdm_modelFull) @ (np.linalg.inv(perm_fact_behav))\n",
    "    # making distance vector out of that permutated behavioral RDM that will be used to run the RSA - i.e. that will be correlated to the distance vector of the brain RDM\n",
    "    behav_corrected_perm_vec = df_behav_corrected_perm.to_numpy()[np.triu_indices(len(df_behav_corrected_perm.to_numpy()[0]), 1)]\n",
    "    # creating vessels that will contain the values constituting the r coefficients of all 268 parcels for a given permutation\n",
    "    temp_r_coef_for_one_perm_behav = []\n",
    "\n",
    "    # loop over parcelID\n",
    "    for parc in parcel_ID:\n",
    "        # RSA: compute the correlation between the reordered behavioral RDM (vector) and the non-reordered brain RDM (vector)\n",
    "        corr_behav = scipy.stats.spearmanr(behav_corrected_perm_vec, temp_rdm_df_vec[str(parc)]) \n",
    "        # append the correlation coefficient ([0] of corr) to the list that will contain the values making the null distribution of surrogate correlation values \n",
    "        temp_r_coef_for_one_perm_behav.append(corr_behav[0])\n",
    "\n",
    "    # retrieve the max R from this permutation and append to overall array of max values --> only if multiple conditions\n",
    "    temp_max_value = np.max(temp_r_coef_for_one_perm_behav)\n",
    "    family_wise_null_distr_behav.append(temp_max_value) \n",
    "    \n",
    "    ### Unnecessary step to later build the 268 null distributions by condition/parcel\n",
    "    list_null_distr_to_transpose.append(temp_r_coef_for_one_perm_behav)\n",
    "\n",
    "print('permutations done') \n",
    "\n",
    "# vessel for RSA results\n",
    "RSA_correlation_all_res = {}  # a dictionary for all Spearman correlations of connectome RDMs with behav RDM\n",
    "RSA_correlation_sig_res = {}  # a dictionary for ONLY statistically significant Spearman correlations of connectome RDMs with behav RDM (at the FWE-corrected 0.05 threshold)\n",
    "\n",
    "for parc in parcel_ID:           \n",
    "    # compute and save correlation results (RSA between parcelwiseConnectivity RDM and group-model RDM)\n",
    "    print('-- parcel: {ID}, statistic calculation(step 4/4)'.format(ID=parc))\n",
    "    # statistic & save as value in keyParcel\n",
    "    all_parcsDF_resUncor[str(parc)] = scipy.stats.spearmanr(temp_rdm_df_vec[str(parc)], rdm_modelFull_vec)\n",
    "    ## permutation testing correction\n",
    "    # the key of the dictionary has another dictionary as value\n",
    "    RSA_correlation_all_res[str(parc)] = {} \n",
    "    RSA_correlation_all_res[str(parc)]['corr_coef'] = all_parcsDF_resUncor[str(parc)][0]\n",
    "    RSA_correlation_all_res[str(parc)]['dist_coeff'] = 1 - all_parcsDF_resUncor[str(parc)][0]\n",
    "    RSA_correlation_all_res[str(parc)]['p-value'] = calc_pvalue(family_wise_null_distr_behav, all_parcsDF_resUncor[str(parc)][0])\n",
    "    ##Making dictionary for only statistically significant (FWE-corrected p < 0.05 level)\n",
    "    if RSA_correlation_all_res[str(parc)]['p-value'] <= 0.05:\n",
    "        # the key of the dictionary has another dictionary as value\n",
    "        RSA_correlation_sig_res[str(parc)] = {}  \n",
    "        RSA_correlation_sig_res[str(parc)]['corr_coef'] = all_parcsDF_resUncor[str(parc)][0]\n",
    "        RSA_correlation_sig_res[str(parc)]['dist_coef'] = 1 - all_parcsDF_resUncor[str(parc)][0]\n",
    "        RSA_correlation_sig_res[str(parc)]['p-value'] = RSA_correlation_all_res[str(parc)]['p-value']\n",
    "print('done')\n",
    "#\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60aad7",
   "metadata": {},
   "source": [
    "### Save results of Positive Mood-RSFC RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save results for depression score RSA\n",
    "# File paths\n",
    "file1_path = \"outputdelta_posmood_seuclidean_twotaileduncorrected.txt\"\n",
    "file2_path = \"outputdelta_posmood_seuclidean_twotailedFWEcorrected.txt\"\n",
    "\n",
    "# Remove files if they exist\n",
    "if os.path.exists(file1_path):\n",
    "    os.remove(file1_path)\n",
    "if os.path.exists(file2_path):\n",
    "    os.remove(file2_path)\n",
    "    \n",
    "for key in all_parcsDF_resUncor:\n",
    "    with open(file1_path, \"a\") as file1, open(file2_path, \"a\") as file2:\n",
    "        file1.write('parcel {key}: {value}\\n'.format(key=str(int(key)+1), value=all_parcsDF_resUncor[key]))\n",
    "        file2.write('parcel {key}: rho {value1}, p-value {value2}\\n'.format(key=str(int(key)+1), value1=RSA_correlation_all_res[key]['corr_coef'], value2=RSA_correlation_all_res[key]['p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892b357",
   "metadata": {},
   "source": [
    "### Save results of Negative Mood-RSFC RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save results for depression score RSA\n",
    "# File paths\n",
    "file1_path = \"outputdelta_negmood_seuclidean_twotaileduncorrected.txt\"\n",
    "file2_path = \"outputdelta_negmood_seuclidean_twotailedFWEcorrected.txt\"\n",
    "\n",
    "# Remove files if they exist\n",
    "if os.path.exists(file1_path):\n",
    "    os.remove(file1_path)\n",
    "if os.path.exists(file2_path):\n",
    "    os.remove(file2_path)\n",
    "    \n",
    "for key in all_parcsDF_resUncor:\n",
    "    with open(file1_path, \"a\") as file1, open(file2_path, \"a\") as file2:\n",
    "        file1.write('parcel {key}: {value}\\n'.format(key=str(int(key)+1), value=all_parcsDF_resUncor[key]))\n",
    "        file2.write('parcel {key}: rho {value1}, p-value {value2}\\n'.format(key=str(int(key)+1), value1=RSA_correlation_all_res[key]['corr_coef'], value2=RSA_correlation_all_res[key]['p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a0754",
   "metadata": {},
   "source": [
    "### Save results of Depressive Score-RSFC RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39954d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save results for depression score RSA\n",
    "# File paths\n",
    "file1_path = \"outputdelta_BDI_seuclidean_twotaileduncorrected.txt\"\n",
    "file2_path = \"outputdelta_BDI_seuclidean_twotailedFWEcorrected.txt\"\n",
    "\n",
    "# Remove files if they exist\n",
    "if os.path.exists(file1_path):\n",
    "    os.remove(file1_path)\n",
    "if os.path.exists(file2_path):\n",
    "    os.remove(file2_path)\n",
    "    \n",
    "for key in all_parcsDF_resUncor:\n",
    "    with open(file1_path, \"a\") as file1, open(file2_path, \"a\") as file2:\n",
    "        file1.write('parcel {key}: {value}\\n'.format(key=str(int(key)+1), value=all_parcsDF_resUncor[key]))\n",
    "        file2.write('parcel {key}: rho {value1}, p-value {value2}\\n'.format(key=str(int(key)+1), value1=RSA_correlation_all_res[key]['corr_coef'], value2=RSA_correlation_all_res[key]['p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56652ff0",
   "metadata": {},
   "source": [
    "### Save results of Emotion Recognition Accuracy-RSFC RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save results for depression score RSA\n",
    "# File paths\n",
    "file1_path = \"outputdelta_emorecacc_seuclidean_twotaileduncorrected.txt\"\n",
    "file2_path = \"outputdelta_emorecacc_seuclidean_twotailedFWEcorrected.txt\"\n",
    "\n",
    "# Remove files if they exist\n",
    "if os.path.exists(file1_path):\n",
    "    os.remove(file1_path)\n",
    "if os.path.exists(file2_path):\n",
    "    os.remove(file2_path)\n",
    "    \n",
    "for key in all_parcsDF_resUncor:\n",
    "    with open(file1_path, \"a\") as file1, open(file2_path, \"a\") as file2:\n",
    "        file1.write('parcel {key}: {value}\\n'.format(key=str(int(key)+1), value=all_parcsDF_resUncor[key]))\n",
    "        file2.write('parcel {key}: rho {value1}, p-value {value2}\\n'.format(key=str(int(key)+1), value1=RSA_correlation_all_res[key]['corr_coef'], value2=RSA_correlation_all_res[key]['p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2e599",
   "metadata": {},
   "source": [
    "### Save results of Emotion Recognition Times-RSFC RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9590b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for Emotion Recognition Response Times\n",
    "# File paths\n",
    "file1_path = \"outputdelta_emorecrt_seuclidean_twotaileduncorrected.txt\"\n",
    "file2_path = \"outputdelta_emorecrt_seuclidean_twotailedFWEcorrected.txt\"\n",
    "\n",
    "# Remove files if they exist\n",
    "if os.path.exists(file1_path):\n",
    "    os.remove(file1_path)\n",
    "if os.path.exists(file2_path):\n",
    "    os.remove(file2_path)\n",
    "    \n",
    "for key in all_parcsDF_resUncor:\n",
    "    with open(file1_path, \"a\") as file1, open(file2_path, \"a\") as file2:\n",
    "        file1.write('parcel {key}: {value}\\n'.format(key=str(int(key)+1), value=all_parcsDF_resUncor[key]))\n",
    "        file2.write('parcel {key}: rho {value1}, p-value {value2}\\n'.format(key=str(int(key)+1), value1=RSA_correlation_all_res[key]['corr_coef'], value2=RSA_correlation_all_res[key]['p-value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d363c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f02061",
   "metadata": {},
   "source": [
    "## Create histrogram of 'winner' null distribution across all 268 parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the null distribution of the surrogate Spearman correlation values\n",
    "plt.hist(family_wise_null_distr_behav, bins=50, alpha = 0.25)\n",
    "plt.title('Family-wise null distribution of surrogate Spearman correlation values for CogAC network (state)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Mean:  \", round(np.mean(family_wise_null_distr_behav),3))\n",
    "print(\"Median:\", round(np.median(family_wise_null_distr_behav),3))\n",
    "print(\"Minimum:\", round(np.min(family_wise_null_distr_behav),3))\n",
    "print(\"Maximum:\", round(np.max(family_wise_null_distr_behav),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7b00e",
   "metadata": {},
   "source": [
    "### for investigating all null distributions seperate by parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contain a list of lists representing the null distributions made across 268 parcels\n",
    "list_null_distr = np.array(list_null_distr_to_transpose).T\n",
    "list_null_distr = list_null_distr.tolist()\n",
    "# dataframe representing the null distributions made across 268 parcels\n",
    "df_list_null_distr = pd.DataFrame(list_null_distr)\n",
    "df_list_null_distr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
